{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Finding minimum Pledge",
   "id": "15bb5cc76778ed18"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T21:00:00.502531Z",
     "start_time": "2024-08-12T21:00:00.499202Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_min_pledge(pledge_list):\n",
    "    # Filter out non-positive numbers and sort the list\n",
    "    positive_pledges = sorted([p for p in pledge_list if p > 0])\n",
    "\n",
    "    # If there is no positive numbers the smallest pledge is 1\n",
    "    if not positive_pledges:\n",
    "        return 1\n",
    "\n",
    "    # Go through the sorted list and find the first missing positive number\n",
    "    min_pledge = 1\n",
    "    for pledge in positive_pledges:\n",
    "        if pledge == min_pledge:\n",
    "            min_pledge += 1\n",
    "        elif pledge > min_pledge:\n",
    "            break\n",
    "\n",
    "    return min_pledge"
   ],
   "id": "48c8612e482a1b6f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T21:00:00.505446Z",
     "start_time": "2024-08-12T21:00:00.503403Z"
    }
   },
   "cell_type": "code",
   "source": [
    "assert find_min_pledge([1, 3, 6, 4, 1, 2]) == 5\n",
    "assert find_min_pledge([1, 2, 3]) == 4\n",
    "assert find_min_pledge([-1, -3]) == 1"
   ],
   "id": "372400f38ea142ca",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Getting headlines",
   "id": "938eaf0fa8a01477"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T21:00:00.567656Z",
     "start_time": "2024-08-12T21:00:00.516357Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def get_headlines(rss_url):\n",
    "    \"\"\"\n",
    "    Fetches and parses the RSS feed from the provided URL and returns a list of article titles.\n",
    "\n",
    "    param:\n",
    "        rss_url (str): The URL of the RSS feed to fetch and parse.\n",
    "\n",
    "    return:\n",
    "        list of str: A list of article titles extracted from the RSS feed.\n",
    "    \"\"\"\n",
    "    # Fetch the RSS feed content\n",
    "    response = requests.get(rss_url)\n",
    "    if response.status_code != 200:\n",
    "        return []  # Return an empty list if the request fails\n",
    "\n",
    "    # Parse the XML content\n",
    "    root = ET.fromstring(response.content)\n",
    "\n",
    "    # Extract the titles\n",
    "    headlines = []\n",
    "    for item in root.findall(\".//item/title\"):\n",
    "        headlines.append(item.text)\n",
    "\n",
    "    return headlines"
   ],
   "id": "cb012ca50ec3279",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T21:00:01.076115Z",
     "start_time": "2024-08-12T21:00:00.568382Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "google_news_url = \"https://news.google.com/news/rss\"\n",
    "print(get_headlines(google_news_url))"
   ],
   "id": "bfa978893269dae3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'Significant' earthquake rocks Los Angeles - ABC News\", \"Top Ukrainian commander says his forces now control almost 390 square miles of Russia's Kursk region - The Associated Press\", 'Defense secretary orders submarine to Middle East, accelerates arrival of strike group ahead of anticipated Iran attack - CNN', 'EU warns Elon Musk ahead of Trump interview to keep hate speech off X - CNBC', 'Iran gives few clues as region awaits military response to Israel - Financial Times', 'Walz Slammed by Former Battalion Leader: ‘He Did Not Earn the Rank’ - The Daily Beast', 'Joe Biden would sign a bill eliminating a tax on tips, White House says - The Hill', '‘We gotta be somewhere’: Homeless Californians react to Newsom’s crackdown - CalMatters', 'Trump falsely claims Harris campaign used AI to fake crowd in Detroit - CBS News', 'Crews begin demolishing Texas church where gunman killed more than two dozen in 2017 - The Associated Press', 'Hamas Refuses to Attend Upcoming Cease-Fire, Hostage Talks - Foreign Policy', 'Evacuations ordered near Athens as Greek authorities try to contain wildfires - CNN', 'Zaporizhzhia nuclear plant: Ukraine and Russia trade blame over fire - BBC.com', 'Heat Contributed to 47,000 Deaths in Europe Last Year, but Relief Programs Helped - The New York Times', \"Dow Jones Dips But This AI Stock Rockets; Donald Trump Stock Dives After Loss (Live Coverage) - Investor's Business Daily\", \"Trump wants a role in setting interest rates. Some economists say it's a bad idea - ABC News\", 'Blink Fitness — whose gyms charged as little as $15 a month — files for bankruptcy - New York Post ', 'B. Riley Suspends Dividend, Warns of Loss on FRG Investment - Yahoo Finance', 'Everything to expect at Made by Google 2024: Pixel 9 Pro, Fold, Gemini, Watch 3, and more - ZDNet', 'The OnePlus Nord 4 does one thing better than any other Android phone - Digital Trends', 'Lossless Scaling Frame Generation 2.3 Adds X4 FG Mode, Initial NVIDIA G-Sync Support - Wccftech', \"AI Magical Thinking, Asking Chatbots About Sex and Homework, Meta Wants Awkwafina's Voice - CNET\", 'Blake Lively and Ryan Reynolds mark first married couple to top box office in 34 years - USA TODAY', '‘Pokémon’ star Rachael Lillis, who voiced Jessie and Misty, dead at 46: ‘Her light no longer shines’ - New York Post ', 'Emotional Miley Cyrus accepts Disney Legend award - BBC.com', 'Elle King Doesn’t ‘Want to Be Associated’ With ‘Toxic’ Father Rob Schneider - Billboard', 'Red Sox OF Duran suspended for anti-gay slur - ESPN', \"Haason Reddick requests trade: Jets 'will not' deal star acquired in offseason; five potential landing spots - CBS Sports\", 'How Los Angeles Aims to Make a Profit on the 2028 Olympics - The New York Times', 'Ohio State extends record AP Top 25 streak; Ole Miss has best preseason ranking since Archie Manning - The Associated Press', 'New hope of finding life on Mars after indication of water, scientists say - The Guardian', 'Dramatic northern lights bathed U.S. skies during Perseid meteor shower - The Washington Post', 'Rare, severe geomagnetic storm hits Earth: Will it impact the grid? - The Hill', 'With Starliner stuck in space, has NASA’s safety culture changed since Columbia? - Ars Technica', 'Global cancer deaths among men projected to increase by 93% by 2050, study finds - CNN', 'Harms linked to drinking may be greater for people in worse health, study finds - The Guardian', '5 Diagnosed With Legionnaires Disease After Visiting NH Town - Patch', \"'Zika-like' mosquito-borne virus has spread into Europe, health officials warn - Fox News\"]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "8b5c05b729c4ad84"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Streaming Payments Processor",
   "id": "a55919886d42a1ef"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T21:00:01.079357Z",
     "start_time": "2024-08-12T21:00:01.077177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_payments_storage():\n",
    "    \"\"\"\n",
    "    @returns an instance of\n",
    "    https://docs.python.org/3/library/io.html#io.BufferedWriter\n",
    "    \"\"\"\n",
    "# Sample implementation to make the code run in coderpad.\n",
    "# Do not rely on this exact implementation.\n",
    "    return open('/dev/null', 'wb')\n",
    "\n",
    "# This is a library function, you can't modify it.\n",
    "def stream_payments_to_storage(storage):\n",
    "    \"\"\"\n",
    "    \n",
    "    Loads payments and writes them to the `storage`.\n",
    "    Python\n",
    "    Assignment for\n",
    "    Associate Data Engineer role\n",
    "    Returns when all payments have been written.\n",
    "    @parameter `storage`: is an instance of\n",
    "    https://docs.python.org/3/library/io.html#io.BufferedWriter\n",
    "    \"\"\"\n",
    "# Sample implementation to make the code run in coderpad.\n",
    "# Do not rely on this exact implementation\n",
    "    for i in range(10):\n",
    "        storage.write(bytes([1, 2, 3, 4, 5]))"
   ],
   "id": "7746ebaa48af1a79",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T21:00:01.083364Z",
     "start_time": "2024-08-12T21:00:01.080949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_payments():\n",
    "    \"\"\"\n",
    "    Processes payments by streaming them to storage and prints the checksum of all bytes written.\n",
    "    \n",
    "    The function calculates the checksum as a simple arithmetic sum of the byte values written by\n",
    "    the `stream_payments_to_storage()` call. The existing functionality of streaming payments to storage \n",
    "    is preserved, and the checksum is printed at the end.\n",
    "\n",
    "    Example:\n",
    "        If the bytes [1, 2, 3, 4, 5] were written in each iteration, and there were 10 iterations,\n",
    "        the checksum would be 150.\n",
    "    \"\"\"\n",
    "    \n",
    "    class ChecksumWriter:\n",
    "        def __init__(self, wrapped_storage):\n",
    "            self.wrapped_storage = wrapped_storage\n",
    "            self.checksum = 0\n",
    "        \n",
    "        def write(self, buffer):\n",
    "            self.checksum += sum(buffer)\n",
    "            self.wrapped_storage.write(buffer)\n",
    "        \n",
    "        def close(self):\n",
    "            self.wrapped_storage.close()\n",
    "    \n",
    "    # Get the storage\n",
    "    storage = get_payments_storage()\n",
    "    \n",
    "    # Wrap the storage to calculate checksum\n",
    "    checksum_writer = ChecksumWriter(storage)\n",
    "    \n",
    "    # Stream payments to storage\n",
    "    stream_payments_to_storage(checksum_writer)\n",
    "    \n",
    "    # Print the checksum of all bytes written\n",
    "    print(checksum_writer.checksum)\n",
    "    checksum_writer.close()"
   ],
   "id": "953167de450bf716",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T21:00:01.086220Z",
     "start_time": "2024-08-12T21:00:01.083844Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "process_payments()"
   ],
   "id": "87374e8b47c6603",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Streaming Payments Processor, two vendors edition.",
   "id": "4c3b4260c0b7274"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T21:00:01.088871Z",
     "start_time": "2024-08-12T21:00:01.086872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import io\n",
    "\n",
    "# This is a library function, you can't modify it.\n",
    "def stream_payments(callback_fn):\n",
    "    \"\"\"\n",
    "    Reads payments from a payment processor and calls `callback_fn(amount)`\n",
    "    for each payment.\n",
    "    Returns when there is no more payments.\n",
    "    \"\"\"\n",
    "    for i in range(10):\n",
    "        callback_fn(i)\n",
    "\n",
    "# This is a library function, you can't modify it.\n",
    "def store_payments(amount_iterator):\n",
    "    \"\"\"\n",
    "    Iterates over the payment amounts from amount_iterator\n",
    "    and stores them to a remote system.\n",
    "    \"\"\"\n",
    "    # Sample implementation to make the code run in coderpad.\n",
    "    # Do not rely on this exact implementation.\n",
    "    for i in amount_iterator:\n",
    "        print(i)\n",
    "\n",
    "def callback_example(amount):\n",
    "    print(amount)\n",
    "    return True"
   ],
   "id": "b523ddfdafb450ee",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T21:00:01.091720Z",
     "start_time": "2024-08-12T21:00:01.089594Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def process_payments_2():\n",
    "    \"\"\"\n",
    "    Bridges the gap between `stream_payments()` and `store_payments()` by converting the \n",
    "    callback-based API of `stream_payments()` into an iterator that `store_payments()` can consume.\n",
    "    \n",
    "    The function ensures that payments are streamed and stored efficiently, adhering to the restrictions\n",
    "    of limited memory and single calls to the vendor functions.\n",
    "    \"\"\"\n",
    "    \n",
    "    def payment_generator():\n",
    "        \"\"\"\n",
    "        A generator that yields payment amounts one by one.\n",
    "        This function acts as a bridge, converting the callback pattern into an iterator.\n",
    "        \"\"\"\n",
    "        payment_list = []\n",
    "        def callback(amount):\n",
    "            payment_list.append(amount)\n",
    "\n",
    "        stream_payments(callback)\n",
    "        for payment in payment_list:\n",
    "            yield payment\n",
    "    \n",
    "    # Pass the generator to store_payments\n",
    "    store_payments(payment_generator())"
   ],
   "id": "7a72f4261b3b862a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T21:00:01.097601Z",
     "start_time": "2024-08-12T21:00:01.092743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Example usage\n",
    "process_payments_2()"
   ],
   "id": "1b382c33b843eec3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Code review ",
   "id": "375e0069e5f605a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T21:00:01.109648Z",
     "start_time": "2024-08-12T21:00:01.101722Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_value(data, key, default, lookup=None, mapper=None):\n",
    "    \"\"\"\n",
    "    Finds the value from data associated with key, or default if the\n",
    "    key isn't present.\n",
    "    If a lookup enum is provided, this value is then transformed to its\n",
    "    enum value.\n",
    "    If a mapper function is provided, this value is then transformed\n",
    "    by applying mapper to it.\n",
    "    \"\"\"\n",
    "    return_value = data[key] # Better to use data.get(key, None) as there might no key in dict\n",
    "    if return_value is None or return_value == \"\": # can be used \"if not return_value:\" , covering both\n",
    "        return_value = default\n",
    "    if lookup:\n",
    "        return_value = lookup[return_value]\n",
    "    if mapper:\n",
    "        return_value = mapper(return_value)\n",
    "    return return_value"
   ],
   "id": "81d56f991f3f1620",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T21:00:01.114910Z",
     "start_time": "2024-08-12T21:00:01.112635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def ftp_file_prefix(namespace):\n",
    "    \"\"\"\n",
    "    Given a namespace string with dot-separated tokens, returns the\n",
    "    string with\n",
    "    the final token replaced by 'ftp'.\n",
    "    Example: a.b.c => a.b.ftp\n",
    "    \"\"\"\n",
    "    ## there might be no dot in the string, better handle that case\n",
    "    # tokens = namespace.split(\".\")\n",
    "    # \n",
    "    # # Suggestion: Handle the case where the namespace has only one token\n",
    "    # if len(tokens) > 1:\n",
    "    #     return \".\".join(tokens[:-1]) + '.ftp'\n",
    "    # else:\n",
    "    #     return 'ftp'\n",
    "    return \".\".join(namespace.split(\".\")[:-1]) + '.ftp'"
   ],
   "id": "5a6b6c0704e6b306",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T21:00:01.118451Z",
     "start_time": "2024-08-12T21:00:01.116110Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def string_to_bool(string):\n",
    "    \"\"\"\n",
    "    Returns True if the given string is 'true' case-insensitive,\n",
    "    False if it is\n",
    "    'false' case-insensitive.\n",
    "    Raises ValueError for any other input.\n",
    "    \"\"\"\n",
    "\n",
    "    ## We can fist make lower case, then use dict to return the value \n",
    "    # normalized_str = string.lower()\n",
    "    # \n",
    "    # # Suggestion: Use a dictionary for mapping\n",
    "    # bool_map = {\n",
    "    #     'true': True,\n",
    "    #     'false': False\n",
    "    # }\n",
    "    # \n",
    "    ## Check if the normalized string is in the dictionary and return the corresponding value\n",
    "    # if normalized_str in bool_map:\n",
    "    #     return bool_map[normalized_str]\n",
    "    \n",
    "    if string.lower() == 'true':\n",
    "        return True\n",
    "    if string.lower() == 'false':\n",
    "        return False\n",
    "    raise ValueError(f'String {string} is neither true nor false')"
   ],
   "id": "41c47bff8ddd6dda",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T21:00:01.121910Z",
     "start_time": "2024-08-12T21:00:01.119077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def config_from_dict(dict): ## We can not use \"dict\" as a parameter, we should change it, for example  use \"data\"\n",
    "    \"\"\"\n",
    "    Given a dict representing a row from a namespaces csv file,\n",
    "    returns a DAG configuration as a pair whose first element is the\n",
    "    DAG name\n",
    "    and whose second element is a dict describing the DAG's properties\n",
    "    \"\"\"\n",
    "    # suggestion: check if namespace and Airflow DAG is in data , as they are required\n",
    "    \n",
    "    # if 'Namespace' not in data or 'Airflow DAG' not in data:\n",
    "    #     raise KeyError(\"The keys 'Namespace' and 'Airflow DAG' are required.\")\n",
    "    # \n",
    "    # namespace = data['Namespace']\n",
    "    # dag_name = data['Airflow DAG']\n",
    "    \n",
    "    namespace = dict['Namespace']\n",
    "    \n",
    "    # Suggestion: for not writing call of function so many times, put it into loop. First with defining # #default values.This reducing redundancy.\n",
    "\n",
    "    #     default_values = {\n",
    "    #     \"earliest_available_delta_days\": 0,\n",
    "    #     \"lif_encoding\": 'json',\n",
    "    #     \"earliest_available_time\": '07:00',\n",
    "    #     \"latest_available_time\": '08:00',\n",
    "    #     \"require_schema_match\": 'True',\n",
    "    #     \"schedule_interval\": '1 7 * * * ',\n",
    "    #     \"ftp_file_wildcard\": None,\n",
    "    #     \"ftp_file_prefix\": ftp_file_prefix(namespace)\n",
    "    # }\n",
    "    # \n",
    "    # # Build the properties dictionary\n",
    "    # dag_properties = {\n",
    "    #     key: data.get(key, default) for key, default in default_values.items()\n",
    "    # }\n",
    "    \n",
    "    # # Apply the mapper where necessary\n",
    "    # dag_properties[\"require_schema_match\"] = string_to_bool(dag_properties[\"require_schema_match\"])\n",
    "    # \n",
    "    ## Update the namespace value\n",
    "    # dag_properties[\"namespace\"] = namespace\n",
    "    #\n",
    "    # return (dag_name, dag_properties)\n",
    "    \n",
    "    \n",
    "    return (dict['Airflow DAG'],\n",
    "    {\"earliest_available_delta_days\": 0,\n",
    "     \"lif_encoding\": 'json',\n",
    "     \"earliest_available_time\": get_value(dict, 'Available Start Time', '07:00'),\n",
    "     \"latest_available_time\": get_value(dict, 'Available End Time', '08:00'),\n",
    "     \"require_schema_match\": get_value(dict, 'Requires Schema Match', 'True',  mapper=string_to_bool),\n",
    "     \"schedule_interval\": get_value(dict, 'Schedule', '1 7 * * * '),\n",
    "     \"delta_days\": get_value(dict, 'Delta Days', 'DAY_BEFORE', lookup=DeltaDays), #remove DeltaDays, it                                                                              #is not defined\n",
    "     \"ftp_file_wildcard\": get_value(dict, 'File Naming Pattern', None),\n",
    "     \"ftp_file_prefix\":  get_value(dict, 'FTP File Prefix', ftp_file_prefix(namespace)),\n",
    "     \"namespace\": namespace\n",
    "    }\n",
    "    )"
   ],
   "id": "5e89ee71a67e0a90",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-12T21:00:01.124252Z",
     "start_time": "2024-08-12T21:00:01.122913Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ef4ec715ad90ecf4",
   "outputs": [],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
